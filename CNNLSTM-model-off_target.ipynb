{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format ='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    gpu_num = 1\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[gpu_num], 'GPU')\n",
    "        #tf.config.experimental.set_memory_growth(gpus[gpu_num], True)\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[gpu_num],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4000)])\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_import_preprocessing import import_data_preprocessing\n",
    "from model_define import CNNLSTM_model, CNNLSTM_offtarget_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data :  ['barcode', 'sgRNA', 'target', 'Number_mismatch', 'total_readcnt', 'mutated_readcnt', 'indel_rate']\n"
     ]
    }
   ],
   "source": [
    "train_data_name = 'data/indel_simpletargetcompare_joinedun_081308231007combined.csv'\n",
    "#test_data_name = 'data/nb_data_changed_HT_1-2.csv'\n",
    "preprocessing = import_data_preprocessing(train_data_file_name = train_data_name,\n",
    "                                          #test_data_file_name= test_data_name,\n",
    "                                         )\n",
    "print('train_data : ', preprocessing.train_data_file_sample_column)\n",
    "#print('train_data : ', preprocessing.test_data_file_sample_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['train', 'val', 'total', 'test'])\n",
      "dict_keys(['seq', 'indel_rate', 'indel_class', 'mis_position', 'mis_number', 'read_cnt', 'info'])\n"
     ]
    }
   ],
   "source": [
    "data = preprocessing(sgRNA_column='sgRNA',\n",
    "                     indel_column='indel_rate',\n",
    "                     targetDNA_column='target',\n",
    "                     offtarget=True,\n",
    "                     mismatch_calc=True,\n",
    "                     split_data=0.1,\n",
    "                     sgRNA_have_NGG=False\n",
    "                    )\n",
    "print(data.keys())\n",
    "print(data['train'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73917, 23, 4, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_shape = data['train']['seq'].shape[1:]\n",
    "print(data['train']['seq'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data['train']['seq']\n",
    "class_train = data['train']['indel_class']\n",
    "rate_train = data['train']['indel_rate']\n",
    "\n",
    "X_val = data['val']['seq']\n",
    "class_val = data['val']['indel_class']\n",
    "rate_val = data['val']['indel_rate']\n",
    "\n",
    "X_test = data['val']['seq']\n",
    "class_test = data['val']['indel_class']\n",
    "rate_test = data['val']['indel_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNNLSTM = CNNLSTM_offtarget_model(input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 23, 4, 2)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 23, 1, 128)   1152        input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 23, 1, 128)   2176        input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 23, 1, 128)   3200        input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 23, 1, 128)   4224        input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 23, 1, 128)   5248        input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 23, 1, 128)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 23, 1, 128)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 23, 1, 128)   0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 23, 1, 128)   0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 23, 1, 128)   0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 23, 1, 640)   0           dropout_6[0][0]                  \n",
      "                                                                 dropout_7[0][0]                  \n",
      "                                                                 dropout_8[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "                                                                 dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 23, 640)      0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 23, 256)      918528      lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 23, 8)        0           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 23, 256)      0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 23, 264)      0           reshape_3[0][0]                  \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 23, 128)      33920       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 23, 128)      67712       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 23, 128)      101504      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 23, 128)      135296      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 23, 128)      169088      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 23, 128)      0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 23, 128)      0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 23, 128)      0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 23, 128)      0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 23, 128)      0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 23, 640)      0           dropout_12[0][0]                 \n",
      "                                                                 dropout_13[0][0]                 \n",
      "                                                                 dropout_14[0][0]                 \n",
      "                                                                 dropout_15[0][0]                 \n",
      "                                                                 dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 23, 256)      918528      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 23, 256)      0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 23, 512)      0           dropout_11[0][0]                 \n",
      "                                                                 dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 23, 128)      65664       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 23, 128)      131200      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 23, 128)      196736      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 23, 128)      262272      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 23, 128)      327808      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 23, 128)      0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 23, 128)      0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 23, 128)      0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 23, 128)      0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 23, 128)      0           conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 23, 640)      0           dropout_18[0][0]                 \n",
      "                                                                 dropout_19[0][0]                 \n",
      "                                                                 dropout_20[0][0]                 \n",
      "                                                                 dropout_21[0][0]                 \n",
      "                                                                 dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 23, 256)      918528      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 23, 256)      0           lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 23, 512)      0           dropout_17[0][0]                 \n",
      "                                                                 dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 23, 128)      65664       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 23, 128)      131200      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 23, 128)      196736      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 23, 128)      262272      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 23, 128)      327808      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 23, 128)      0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 23, 128)      0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 23, 128)      0           conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 23, 128)      0           conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 23, 128)      0           conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 23, 640)      0           dropout_24[0][0]                 \n",
      "                                                                 dropout_25[0][0]                 \n",
      "                                                                 dropout_26[0][0]                 \n",
      "                                                                 dropout_27[0][0]                 \n",
      "                                                                 dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   (None, 23, 256)      918528      concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 23, 256)      0           lstm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 23, 512)      0           dropout_23[0][0]                 \n",
      "                                                                 dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 23, 128)      65664       concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 23, 128)      131200      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 23, 128)      196736      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 23, 128)      262272      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 23, 128)      327808      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 23, 128)      0           conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 23, 128)      0           conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 23, 128)      0           conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 23, 128)      0           conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 23, 128)      0           conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 23, 640)      0           dropout_30[0][0]                 \n",
      "                                                                 dropout_31[0][0]                 \n",
      "                                                                 dropout_32[0][0]                 \n",
      "                                                                 dropout_33[0][0]                 \n",
      "                                                                 dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   (None, 23, 256)      918528      concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 23, 256)      0           lstm_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 23, 512)      0           dropout_29[0][0]                 \n",
      "                                                                 dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 512)          0           concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 100)          51300       lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 512)          0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 512)          0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, 100)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 100)          51300       lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 100)          51300       lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 100)          10100       dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 100)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 100)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)            (None, 100)          0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          10100       dropout_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 100)          10100       dropout_38[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 100)          10100       dropout_41[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 100)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 100)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)            (None, 100)          0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "class_1 (Dense)                 (None, 11)           1111        dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "class_2 (Dense)                 (None, 11)           1111        dropout_39[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "class_final (Dense)             (None, 11)           1111        dropout_41[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "rate (Dense)                    (None, 1)            101         dropout_42[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 8,264,934\n",
      "Trainable params: 8,264,934\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "CNNLSTM_model = CNNLSTM.MTL_model()\n",
    "CNNLSTM_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNNLSTM_model.compile(optimizer='adam',\n",
    "              loss={\n",
    "                  #'num_mis': 'categorical_crossentropy',\n",
    "                  'class_1': 'categorical_crossentropy',\n",
    "                  'class_2': 'categorical_crossentropy',\n",
    "                  'class_final': 'categorical_crossentropy',\n",
    "                  'rate': 'mean_squared_error'},\n",
    "              loss_weights={\n",
    "                  #'num_mis': 0.5,\n",
    "                  'class_1': 1,\n",
    "                  'class_2': 1,\n",
    "                  'class_final': 0.5,\n",
    "                  'rate': 1},\n",
    "              metrics={\n",
    "                  #'num_mis': 'accuracy',\n",
    "                  'class_1': \"accuracy\",\n",
    "                  'class_2': \"accuracy\",\n",
    "                  'class_final': \"accuracy\"}\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_weight\n",
      "{0: 0.2465593040554514, 1: 0.6256146795202749, 2: 0.807659527972028, 3: 1.0341223873079828, 4: 1.554772622102562, 5: 1.948876819236448, 6: 3.762445281482236, 7: 4.834336167429693, 8: 5.962490925223844, 9: 7.272432113341204, 10: 0.8288796438543571}\n",
      "sample_weight\n",
      "{0: 0.2465593040554514, 1: 0.6256146795202749, 2: 0.807659527972028, 3: 1.0341223873079828, 4: 1.554772622102562, 5: 1.948876819236448, 6: 3.762445281482236, 7: 4.834336167429693, 8: 5.962490925223844, 9: 7.272432113341204, 10: 0.8288796438543571}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_train_num = class_train.argmax(axis=-1)\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                  np.unique(class_train_num),\n",
    "                                                  class_train_num\n",
    "                                                 )\n",
    "class_weights_dict = dict(enumerate(class_weights))#{ i : class_weights[i] for i in range(11)}\n",
    "print(\"class_weight\")\n",
    "print(class_weights_dict)\n",
    "\n",
    "class_wieghts_dict_tuned = class_weights_dict\n",
    "for i in range(0,11):\n",
    "    multiple_constant = 2\n",
    "    cutoff_class = 5\n",
    "    \n",
    "    if i <=cutoff_class:\n",
    "        class_wieghts_dict_tuned[i] = class_weights_dict[i]#1.0\n",
    "    else:\n",
    "        class_wieghts_dict_tuned[i] = class_weights_dict[i]#multiple_constant*np.tanh((class_weights_dict[i]-2)/2) + multiple_constant\n",
    "    \n",
    "print(\"sample_weight\")\n",
    "print(class_wieghts_dict_tuned)\n",
    "\n",
    "sample_weight = np.array([class_wieghts_dict_tuned[i] for i in class_train_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 73917 samples, validate on 8214 samples\n",
      "Epoch 1/200\n",
      "73917/73917 [==============================] - 47s 637us/sample - loss: 6.1285 - class_1_loss: 2.4064 - class_2_loss: 2.4058 - class_final_loss: 2.4015 - rate_loss: 0.1148 - class_1_accuracy: 0.0788 - class_2_accuracy: 0.0772 - class_final_accuracy: 0.0783 - val_loss: 6.0443 - val_class_1_loss: 2.3639 - val_class_2_loss: 2.3639 - val_class_final_loss: 2.3637 - val_rate_loss: 0.1551 - val_class_1_accuracy: 0.0448 - val_class_2_accuracy: 0.0142 - val_class_final_accuracy: 0.0264\n",
      "Epoch 2/200\n",
      "73917/73917 [==============================] - 31s 422us/sample - loss: 6.0986 - class_1_loss: 2.3985 - class_2_loss: 2.3989 - class_final_loss: 2.3982 - rate_loss: 0.1020 - class_1_accuracy: 0.0630 - class_2_accuracy: 0.0425 - class_final_accuracy: 0.1032 - val_loss: 6.0470 - val_class_1_loss: 2.3637 - val_class_2_loss: 2.3638 - val_class_final_loss: 2.3636 - val_rate_loss: 0.1584 - val_class_1_accuracy: 0.0142 - val_class_2_accuracy: 0.0142 - val_class_final_accuracy: 0.0448\n",
      "Epoch 3/200\n",
      "73917/73917 [==============================] - 32s 439us/sample - loss: 6.0965 - class_1_loss: 2.3985 - class_2_loss: 2.3982 - class_final_loss: 2.3981 - rate_loss: 0.1005 - class_1_accuracy: 0.0704 - class_2_accuracy: 0.0533 - class_final_accuracy: 0.0836 - val_loss: 6.0548 - val_class_1_loss: 2.3636 - val_class_2_loss: 2.3635 - val_class_final_loss: 2.3635 - val_rate_loss: 0.1666 - val_class_1_accuracy: 0.0448 - val_class_2_accuracy: 0.0264 - val_class_final_accuracy: 0.0264\n",
      "Epoch 4/200\n",
      "73917/73917 [==============================] - 33s 441us/sample - loss: 6.0963 - class_1_loss: 2.3983 - class_2_loss: 2.3988 - class_final_loss: 2.3983 - rate_loss: 0.1003 - class_1_accuracy: 0.0357 - class_2_accuracy: 0.0380 - class_final_accuracy: 0.0418 - val_loss: 6.0487 - val_class_1_loss: 2.3636 - val_class_2_loss: 2.3707 - val_class_final_loss: 2.3635 - val_rate_loss: 0.1551 - val_class_1_accuracy: 0.0142 - val_class_2_accuracy: 0.0582 - val_class_final_accuracy: 0.0142\n",
      "Epoch 5/200\n",
      "73917/73917 [==============================] - 33s 441us/sample - loss: 6.0958 - class_1_loss: 2.3989 - class_2_loss: 2.3988 - class_final_loss: 2.3985 - rate_loss: 0.0998 - class_1_accuracy: 0.0642 - class_2_accuracy: 0.0566 - class_final_accuracy: 0.0784 - val_loss: 6.0412 - val_class_1_loss: 2.3633 - val_class_2_loss: 2.3635 - val_class_final_loss: 2.3633 - val_rate_loss: 0.1535 - val_class_1_accuracy: 0.0582 - val_class_2_accuracy: 0.3661 - val_class_final_accuracy: 0.3661\n",
      "Epoch 6/200\n",
      "73917/73917 [==============================] - 33s 443us/sample - loss: 6.0953 - class_1_loss: 2.3986 - class_2_loss: 2.3991 - class_final_loss: 2.3986 - rate_loss: 0.0996 - class_1_accuracy: 0.1408 - class_2_accuracy: 0.0786 - class_final_accuracy: 0.1573 - val_loss: 6.0475 - val_class_1_loss: 2.3636 - val_class_2_loss: 2.3637 - val_class_final_loss: 2.3636 - val_rate_loss: 0.1593 - val_class_1_accuracy: 0.0582 - val_class_2_accuracy: 0.0582 - val_class_final_accuracy: 0.0582\n",
      "Epoch 7/200\n",
      "73917/73917 [==============================] - 33s 441us/sample - loss: 6.0945 - class_1_loss: 2.3983 - class_2_loss: 2.3982 - class_final_loss: 2.3983 - rate_loss: 0.0992 - class_1_accuracy: 0.0663 - class_2_accuracy: 0.0509 - class_final_accuracy: 0.0482 - val_loss: 6.0459 - val_class_1_loss: 2.3636 - val_class_2_loss: 2.3636 - val_class_final_loss: 2.3635 - val_rate_loss: 0.1576 - val_class_1_accuracy: 0.0095 - val_class_2_accuracy: 0.0095 - val_class_final_accuracy: 0.1149\n",
      "Epoch 8/200\n",
      "73917/73917 [==============================] - 33s 443us/sample - loss: 6.0947 - class_1_loss: 2.3982 - class_2_loss: 2.3980 - class_final_loss: 2.3980 - rate_loss: 0.0991 - class_1_accuracy: 0.0389 - class_2_accuracy: 0.0364 - class_final_accuracy: 0.0378 - val_loss: 6.0371 - val_class_1_loss: 2.3636 - val_class_2_loss: 2.3636 - val_class_final_loss: 2.3636 - val_rate_loss: 0.1489 - val_class_1_accuracy: 0.0582 - val_class_2_accuracy: 0.0582 - val_class_final_accuracy: 0.0582\n",
      "Epoch 9/200\n",
      "73917/73917 [==============================] - 33s 441us/sample - loss: 6.0956 - class_1_loss: 2.3992 - class_2_loss: 2.3993 - class_final_loss: 2.3989 - rate_loss: 0.0991 - class_1_accuracy: 0.0711 - class_2_accuracy: 0.0510 - class_final_accuracy: 0.0868 - val_loss: 6.0377 - val_class_1_loss: 2.3636 - val_class_2_loss: 2.3635 - val_class_final_loss: 2.3635 - val_rate_loss: 0.1497 - val_class_1_accuracy: 0.0582 - val_class_2_accuracy: 0.0582 - val_class_final_accuracy: 0.0582\n",
      "Epoch 10/200\n",
      "73917/73917 [==============================] - 33s 443us/sample - loss: 6.0949 - class_1_loss: 2.3985 - class_2_loss: 2.3983 - class_final_loss: 2.3982 - rate_loss: 0.0989 - class_1_accuracy: 0.0922 - class_2_accuracy: 0.0733 - class_final_accuracy: 0.0868 - val_loss: 6.0491 - val_class_1_loss: 2.3635 - val_class_2_loss: 2.3636 - val_class_final_loss: 2.3637 - val_rate_loss: 0.1609 - val_class_1_accuracy: 0.0448 - val_class_2_accuracy: 0.0192 - val_class_final_accuracy: 0.0582\n",
      "Epoch 11/200\n",
      "73917/73917 [==============================] - 32s 439us/sample - loss: 6.0945 - class_1_loss: 2.3982 - class_2_loss: 2.3982 - class_final_loss: 2.3981 - rate_loss: 0.0989 - class_1_accuracy: 0.0907 - class_2_accuracy: 0.0829 - class_final_accuracy: 0.0841 - val_loss: 6.0446 - val_class_1_loss: 2.3636 - val_class_2_loss: 2.3637 - val_class_final_loss: 2.3636 - val_rate_loss: 0.1562 - val_class_1_accuracy: 0.0192 - val_class_2_accuracy: 0.0448 - val_class_final_accuracy: 0.0192\n",
      "Epoch 12/200\n",
      "73917/73917 [==============================] - 32s 438us/sample - loss: 6.0944 - class_1_loss: 2.3983 - class_2_loss: 2.3983 - class_final_loss: 2.3981 - rate_loss: 0.0988 - class_1_accuracy: 0.0379 - class_2_accuracy: 0.0380 - class_final_accuracy: 0.0319 - val_loss: 6.0487 - val_class_1_loss: 2.3636 - val_class_2_loss: 2.3636 - val_class_final_loss: 2.3635 - val_rate_loss: 0.1605 - val_class_1_accuracy: 0.0864 - val_class_2_accuracy: 0.0864 - val_class_final_accuracy: 0.0864\n",
      "Epoch 13/200\n",
      "73917/73917 [==============================] - 32s 435us/sample - loss: 6.0942 - class_1_loss: 2.3983 - class_2_loss: 2.3984 - class_final_loss: 2.3982 - rate_loss: 0.0988 - class_1_accuracy: 0.0449 - class_2_accuracy: 0.0445 - class_final_accuracy: 0.0384 - val_loss: 6.0436 - val_class_1_loss: 2.3636 - val_class_2_loss: 2.3637 - val_class_final_loss: 2.3636 - val_rate_loss: 0.1555 - val_class_1_accuracy: 0.1480 - val_class_2_accuracy: 0.1480 - val_class_final_accuracy: 0.1480\n",
      "Epoch 14/200\n",
      "73917/73917 [==============================] - 32s 435us/sample - loss: 6.0941 - class_1_loss: 2.3980 - class_2_loss: 2.3980 - class_final_loss: 2.3979 - rate_loss: 0.0988 - class_1_accuracy: 0.0974 - class_2_accuracy: 0.0961 - class_final_accuracy: 0.0993 - val_loss: 6.0463 - val_class_1_loss: 2.3637 - val_class_2_loss: 2.3636 - val_class_final_loss: 2.3636 - val_rate_loss: 0.1579 - val_class_1_accuracy: 0.0095 - val_class_2_accuracy: 0.0264 - val_class_final_accuracy: 0.0264\n",
      "Epoch 15/200\n",
      "73917/73917 [==============================] - 33s 443us/sample - loss: 6.0944 - class_1_loss: 2.3981 - class_2_loss: 2.3983 - class_final_loss: 2.3983 - rate_loss: 0.0989 - class_1_accuracy: 0.0706 - class_2_accuracy: 0.0691 - class_final_accuracy: 0.0653 - val_loss: 6.0433 - val_class_1_loss: 2.3634 - val_class_2_loss: 2.3634 - val_class_final_loss: 2.3634 - val_rate_loss: 0.1556 - val_class_1_accuracy: 0.0448 - val_class_2_accuracy: 0.0448 - val_class_final_accuracy: 0.0448\n",
      "Epoch 16/200\n",
      "73917/73917 [==============================] - 33s 440us/sample - loss: 6.0949 - class_1_loss: 2.3991 - class_2_loss: 2.3982 - class_final_loss: 2.3984 - rate_loss: 0.0988 - class_1_accuracy: 0.0608 - class_2_accuracy: 0.0668 - class_final_accuracy: 0.0593 - val_loss: 6.0450 - val_class_1_loss: 2.3635 - val_class_2_loss: 2.3634 - val_class_final_loss: 2.3634 - val_rate_loss: 0.1571 - val_class_1_accuracy: 0.0142 - val_class_2_accuracy: 0.0142 - val_class_final_accuracy: 0.0448\n",
      "Epoch 17/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73917/73917 [==============================] - 33s 440us/sample - loss: 6.0940 - class_1_loss: 2.3978 - class_2_loss: 2.3978 - class_final_loss: 2.3979 - rate_loss: 0.0988 - class_1_accuracy: 0.0569 - class_2_accuracy: 0.0517 - class_final_accuracy: 0.0554 - val_loss: 6.0479 - val_class_1_loss: 2.3637 - val_class_2_loss: 2.3637 - val_class_final_loss: 2.3637 - val_rate_loss: 0.1594 - val_class_1_accuracy: 0.0095 - val_class_2_accuracy: 0.0095 - val_class_final_accuracy: 0.0095\n",
      "Epoch 18/200\n",
      "73917/73917 [==============================] - 32s 436us/sample - loss: 6.0941 - class_1_loss: 2.3982 - class_2_loss: 2.3983 - class_final_loss: 2.3982 - rate_loss: 0.0988 - class_1_accuracy: 0.1152 - class_2_accuracy: 0.1089 - class_final_accuracy: 0.1081 - val_loss: 6.0455 - val_class_1_loss: 2.3635 - val_class_2_loss: 2.3633 - val_class_final_loss: 2.3635 - val_rate_loss: 0.1575 - val_class_1_accuracy: 0.0142 - val_class_2_accuracy: 0.0192 - val_class_final_accuracy: 0.0264\n",
      "Epoch 19/200\n",
      "73917/73917 [==============================] - 33s 443us/sample - loss: 6.0944 - class_1_loss: 2.3986 - class_2_loss: 2.3983 - class_final_loss: 2.3983 - rate_loss: 0.0988 - class_1_accuracy: 0.0391 - class_2_accuracy: 0.0463 - class_final_accuracy: 0.0767 - val_loss: 6.0452 - val_class_1_loss: 2.3639 - val_class_2_loss: 2.3638 - val_class_final_loss: 2.3637 - val_rate_loss: 0.1565 - val_class_1_accuracy: 0.0095 - val_class_2_accuracy: 0.0095 - val_class_final_accuracy: 0.0448\n",
      "Epoch 20/200\n",
      "73917/73917 [==============================] - 32s 439us/sample - loss: 6.0941 - class_1_loss: 2.3980 - class_2_loss: 2.3980 - class_final_loss: 2.3980 - rate_loss: 0.0988 - class_1_accuracy: 0.0389 - class_2_accuracy: 0.0457 - class_final_accuracy: 0.0415 - val_loss: 6.0463 - val_class_1_loss: 2.3637 - val_class_2_loss: 2.3638 - val_class_final_loss: 2.3637 - val_rate_loss: 0.1577 - val_class_1_accuracy: 0.0095 - val_class_2_accuracy: 0.0095 - val_class_final_accuracy: 0.0095\n",
      "Epoch 21/200\n",
      "73917/73917 [==============================] - 33s 442us/sample - loss: 6.0941 - class_1_loss: 2.3985 - class_2_loss: 2.3984 - class_final_loss: 2.3984 - rate_loss: 0.0988 - class_1_accuracy: 0.0368 - class_2_accuracy: 0.0424 - class_final_accuracy: 0.0429 - val_loss: 6.0446 - val_class_1_loss: 2.3635 - val_class_2_loss: 2.3635 - val_class_final_loss: 2.3635 - val_rate_loss: 0.1566 - val_class_1_accuracy: 0.0192 - val_class_2_accuracy: 0.1121 - val_class_final_accuracy: 0.1121\n",
      "Epoch 22/200\n",
      "73917/73917 [==============================] - 32s 437us/sample - loss: 6.0940 - class_1_loss: 2.3978 - class_2_loss: 2.3977 - class_final_loss: 2.3977 - rate_loss: 0.0988 - class_1_accuracy: 0.0360 - class_2_accuracy: 0.0340 - class_final_accuracy: 0.0369 - val_loss: 6.0457 - val_class_1_loss: 2.3634 - val_class_2_loss: 2.3634 - val_class_final_loss: 2.3634 - val_rate_loss: 0.1579 - val_class_1_accuracy: 0.0864 - val_class_2_accuracy: 0.0864 - val_class_final_accuracy: 0.0864\n",
      "Epoch 23/200\n",
      "73917/73917 [==============================] - 32s 429us/sample - loss: 6.0939 - class_1_loss: 2.3980 - class_2_loss: 2.3980 - class_final_loss: 2.3980 - rate_loss: 0.0988 - class_1_accuracy: 0.0431 - class_2_accuracy: 0.0477 - class_final_accuracy: 0.0449 - val_loss: 6.0420 - val_class_1_loss: 2.3633 - val_class_2_loss: 2.3633 - val_class_final_loss: 2.3633 - val_rate_loss: 0.1545 - val_class_1_accuracy: 0.1149 - val_class_2_accuracy: 0.1149 - val_class_final_accuracy: 0.1149\n",
      "Epoch 24/200\n",
      "73917/73917 [==============================] - 32s 428us/sample - loss: 6.0950 - class_1_loss: 2.3986 - class_2_loss: 2.3981 - class_final_loss: 2.3980 - rate_loss: 0.0988 - class_1_accuracy: 0.0725 - class_2_accuracy: 0.0918 - class_final_accuracy: 0.0932 - val_loss: 6.0468 - val_class_1_loss: 2.3634 - val_class_2_loss: 2.3635 - val_class_final_loss: 2.3635 - val_rate_loss: 0.1587 - val_class_1_accuracy: 0.0142 - val_class_2_accuracy: 0.0142 - val_class_final_accuracy: 0.0192\n",
      "Epoch 25/200\n",
      "73917/73917 [==============================] - 32s 431us/sample - loss: 6.0942 - class_1_loss: 2.3988 - class_2_loss: 2.3987 - class_final_loss: 2.3987 - rate_loss: 0.0988 - class_1_accuracy: 0.0403 - class_2_accuracy: 0.0414 - class_final_accuracy: 0.0532 - val_loss: 6.0468 - val_class_1_loss: 2.3637 - val_class_2_loss: 2.3636 - val_class_final_loss: 2.3636 - val_rate_loss: 0.1586 - val_class_1_accuracy: 0.0095 - val_class_2_accuracy: 0.0264 - val_class_final_accuracy: 0.0264\n",
      "Epoch 26/200\n",
      "73917/73917 [==============================] - 32s 429us/sample - loss: 6.0944 - class_1_loss: 2.3984 - class_2_loss: 2.3986 - class_final_loss: 2.3983 - rate_loss: 0.0988 - class_1_accuracy: 0.0926 - class_2_accuracy: 0.0859 - class_final_accuracy: 0.0897 - val_loss: 6.0498 - val_class_1_loss: 2.3637 - val_class_2_loss: 2.3637 - val_class_final_loss: 2.3637 - val_rate_loss: 0.1613 - val_class_1_accuracy: 0.0095 - val_class_2_accuracy: 0.0095 - val_class_final_accuracy: 0.0095\n",
      "Epoch 27/200\n",
      "73917/73917 [==============================] - 31s 423us/sample - loss: 6.0944 - class_1_loss: 2.3984 - class_2_loss: 2.3979 - class_final_loss: 2.3980 - rate_loss: 0.0988 - class_1_accuracy: 0.0448 - class_2_accuracy: 0.0474 - class_final_accuracy: 0.0379 - val_loss: 6.0500 - val_class_1_loss: 2.3636 - val_class_2_loss: 2.3634 - val_class_final_loss: 2.3635 - val_rate_loss: 0.1620 - val_class_1_accuracy: 0.0142 - val_class_2_accuracy: 0.3661 - val_class_final_accuracy: 0.1149\n",
      "Epoch 28/200\n",
      "73917/73917 [==============================] - 32s 428us/sample - loss: 6.0948 - class_1_loss: 2.3983 - class_2_loss: 2.3980 - class_final_loss: 2.3984 - rate_loss: 0.0989 - class_1_accuracy: 0.0387 - class_2_accuracy: 0.0454 - class_final_accuracy: 0.0581 - val_loss: 6.0493 - val_class_1_loss: 2.3637 - val_class_2_loss: 2.3636 - val_class_final_loss: 2.3638 - val_rate_loss: 0.1609 - val_class_1_accuracy: 0.0095 - val_class_2_accuracy: 0.1149 - val_class_final_accuracy: 0.0582\n",
      "Epoch 29/200\n",
      "73917/73917 [==============================] - 32s 430us/sample - loss: 6.0946 - class_1_loss: 2.3987 - class_2_loss: 2.3981 - class_final_loss: 2.3982 - rate_loss: 0.0988 - class_1_accuracy: 0.0355 - class_2_accuracy: 0.0560 - class_final_accuracy: 0.0558 - val_loss: 6.0447 - val_class_1_loss: 2.3635 - val_class_2_loss: 2.3633 - val_class_final_loss: 2.3634 - val_rate_loss: 0.1569 - val_class_1_accuracy: 0.1480 - val_class_2_accuracy: 0.0142 - val_class_final_accuracy: 0.1121\n",
      "Epoch 30/200\n",
      "73917/73917 [==============================] - 31s 425us/sample - loss: 6.0948 - class_1_loss: 2.3977 - class_2_loss: 2.3981 - class_final_loss: 2.3980 - rate_loss: 0.0988 - class_1_accuracy: 0.0275 - class_2_accuracy: 0.0314 - class_final_accuracy: 0.0343 - val_loss: 6.0434 - val_class_1_loss: 2.3633 - val_class_2_loss: 2.3633 - val_class_final_loss: 2.3631 - val_rate_loss: 0.1560 - val_class_1_accuracy: 0.1149 - val_class_2_accuracy: 0.0192 - val_class_final_accuracy: 0.1149\n",
      "Epoch 31/200\n",
      "73917/73917 [==============================] - 32s 431us/sample - loss: 6.0946 - class_1_loss: 2.3985 - class_2_loss: 2.3984 - class_final_loss: 2.3983 - rate_loss: 0.0988 - class_1_accuracy: 0.0624 - class_2_accuracy: 0.0444 - class_final_accuracy: 0.0600 - val_loss: 6.0458 - val_class_1_loss: 2.3635 - val_class_2_loss: 2.3635 - val_class_final_loss: 2.3636 - val_rate_loss: 0.1576 - val_class_1_accuracy: 0.0142 - val_class_2_accuracy: 0.0264 - val_class_final_accuracy: 0.1480\n",
      "Epoch 32/200\n",
      "73917/73917 [==============================] - 32s 431us/sample - loss: 6.0943 - class_1_loss: 2.3988 - class_2_loss: 2.3988 - class_final_loss: 2.3987 - rate_loss: 0.0988 - class_1_accuracy: 0.0722 - class_2_accuracy: 0.0296 - class_final_accuracy: 0.0558 - val_loss: 6.0471 - val_class_1_loss: 2.3635 - val_class_2_loss: 2.3636 - val_class_final_loss: 2.3636 - val_rate_loss: 0.1589 - val_class_1_accuracy: 0.0864 - val_class_2_accuracy: 0.0864 - val_class_final_accuracy: 0.0864\n",
      "Epoch 33/200\n",
      "73917/73917 [==============================] - 32s 431us/sample - loss: 6.0943 - class_1_loss: 2.3979 - class_2_loss: 2.3981 - class_final_loss: 2.3979 - rate_loss: 0.0988 - class_1_accuracy: 0.0778 - class_2_accuracy: 0.0643 - class_final_accuracy: 0.0809 - val_loss: 6.0480 - val_class_1_loss: 2.3637 - val_class_2_loss: 2.3638 - val_class_final_loss: 2.3636 - val_rate_loss: 0.1595 - val_class_1_accuracy: 0.3661 - val_class_2_accuracy: 0.0095 - val_class_final_accuracy: 0.0864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/200\n",
      "73917/73917 [==============================] - 32s 432us/sample - loss: 6.0944 - class_1_loss: 2.3978 - class_2_loss: 2.3981 - class_final_loss: 2.3978 - rate_loss: 0.0988 - class_1_accuracy: 0.0741 - class_2_accuracy: 0.0609 - class_final_accuracy: 0.0834 - val_loss: 6.0470 - val_class_1_loss: 2.3636 - val_class_2_loss: 2.3638 - val_class_final_loss: 2.3636 - val_rate_loss: 0.1586 - val_class_1_accuracy: 0.1121 - val_class_2_accuracy: 0.0095 - val_class_final_accuracy: 0.1121\n",
      "Epoch 35/200\n",
      "73917/73917 [==============================] - 32s 431us/sample - loss: 6.0940 - class_1_loss: 2.3978 - class_2_loss: 2.3978 - class_final_loss: 2.3977 - rate_loss: 0.0988 - class_1_accuracy: 0.0402 - class_2_accuracy: 0.0383 - class_final_accuracy: 0.0393 - val_loss: 6.0428 - val_class_1_loss: 2.3636 - val_class_2_loss: 2.3637 - val_class_final_loss: 2.3637 - val_rate_loss: 0.1546 - val_class_1_accuracy: 0.0864 - val_class_2_accuracy: 0.0864 - val_class_final_accuracy: 0.0864\n",
      "Epoch 36/200\n",
      "73917/73917 [==============================] - 32s 430us/sample - loss: 6.0942 - class_1_loss: 2.3980 - class_2_loss: 2.3983 - class_final_loss: 2.3980 - rate_loss: 0.0988 - class_1_accuracy: 0.1237 - class_2_accuracy: 0.1205 - class_final_accuracy: 0.1235 - val_loss: 6.0462 - val_class_1_loss: 2.3635 - val_class_2_loss: 2.3636 - val_class_final_loss: 2.3635 - val_rate_loss: 0.1583 - val_class_1_accuracy: 0.0264 - val_class_2_accuracy: 0.0264 - val_class_final_accuracy: 0.0264\n",
      "Epoch 37/200\n",
      "73917/73917 [==============================] - 32s 431us/sample - loss: 6.0941 - class_1_loss: 2.3980 - class_2_loss: 2.3981 - class_final_loss: 2.3980 - rate_loss: 0.0988 - class_1_accuracy: 0.0819 - class_2_accuracy: 0.0664 - class_final_accuracy: 0.0797 - val_loss: 6.0471 - val_class_1_loss: 2.3634 - val_class_2_loss: 2.3635 - val_class_final_loss: 2.3635 - val_rate_loss: 0.1591 - val_class_1_accuracy: 0.0264 - val_class_2_accuracy: 0.0264 - val_class_final_accuracy: 0.0264\n",
      "Epoch 38/200\n",
      "73917/73917 [==============================] - 32s 432us/sample - loss: 6.0943 - class_1_loss: 2.3979 - class_2_loss: 2.3982 - class_final_loss: 2.3979 - rate_loss: 0.0988 - class_1_accuracy: 0.0602 - class_2_accuracy: 0.0553 - class_final_accuracy: 0.0617 - val_loss: 6.0492 - val_class_1_loss: 2.3635 - val_class_2_loss: 2.3637 - val_class_final_loss: 2.3636 - val_rate_loss: 0.1610 - val_class_1_accuracy: 0.1121 - val_class_2_accuracy: 0.0095 - val_class_final_accuracy: 0.1121\n",
      "Epoch 39/200\n",
      "73917/73917 [==============================] - 32s 431us/sample - loss: 6.0948 - class_1_loss: 2.3982 - class_2_loss: 2.3983 - class_final_loss: 2.3982 - rate_loss: 0.0988 - class_1_accuracy: 0.0492 - class_2_accuracy: 0.0280 - class_final_accuracy: 0.0466 - val_loss: 6.0423 - val_class_1_loss: 2.3634 - val_class_2_loss: 2.3632 - val_class_final_loss: 2.3634 - val_rate_loss: 0.1547 - val_class_1_accuracy: 0.1480 - val_class_2_accuracy: 0.0264 - val_class_final_accuracy: 0.1480\n",
      "Epoch 40/200\n",
      "73917/73917 [==============================] - 32s 432us/sample - loss: 6.0949 - class_1_loss: 2.3983 - class_2_loss: 2.3985 - class_final_loss: 2.3983 - rate_loss: 0.0988 - class_1_accuracy: 0.0571 - class_2_accuracy: 0.0373 - class_final_accuracy: 0.0600 - val_loss: 6.0502 - val_class_1_loss: 2.3636 - val_class_2_loss: 2.3638 - val_class_final_loss: 2.3638 - val_rate_loss: 0.1616 - val_class_1_accuracy: 0.0095 - val_class_2_accuracy: 0.0095 - val_class_final_accuracy: 0.0095\n",
      "Epoch 41/200\n",
      "73917/73917 [==============================] - 32s 433us/sample - loss: 6.0946 - class_1_loss: 2.3981 - class_2_loss: 2.3984 - class_final_loss: 2.3987 - rate_loss: 0.0988 - class_1_accuracy: 0.1232 - class_2_accuracy: 0.0591 - class_final_accuracy: 0.0891 - val_loss: 6.0464 - val_class_1_loss: 2.3635 - val_class_2_loss: 2.3636 - val_class_final_loss: 2.3638 - val_rate_loss: 0.1583 - val_class_1_accuracy: 0.0864 - val_class_2_accuracy: 0.0864 - val_class_final_accuracy: 0.0864\n",
      "Epoch 42/200\n",
      "73917/73917 [==============================] - 32s 431us/sample - loss: 6.0949 - class_1_loss: 2.3985 - class_2_loss: 2.3988 - class_final_loss: 2.3994 - rate_loss: 0.0989 - class_1_accuracy: 0.0338 - class_2_accuracy: 0.0210 - class_final_accuracy: 0.0282 - val_loss: 6.0436 - val_class_1_loss: 2.3632 - val_class_2_loss: 2.3633 - val_class_final_loss: 2.3631 - val_rate_loss: 0.1563 - val_class_1_accuracy: 0.3661 - val_class_2_accuracy: 0.0142 - val_class_final_accuracy: 0.0192\n",
      "Epoch 43/200\n",
      "73917/73917 [==============================] - 32s 431us/sample - loss: 6.0951 - class_1_loss: 2.3992 - class_2_loss: 2.4000 - class_final_loss: 2.3996 - rate_loss: 0.0988 - class_1_accuracy: 0.0920 - class_2_accuracy: 0.0633 - class_final_accuracy: 0.0667 - val_loss: 6.0469 - val_class_1_loss: 2.3633 - val_class_2_loss: 2.3635 - val_class_final_loss: 2.3632 - val_rate_loss: 0.1592 - val_class_1_accuracy: 0.1480 - val_class_2_accuracy: 0.0142 - val_class_final_accuracy: 0.1480\n",
      "Epoch 44/200\n",
      "73917/73917 [==============================] - 32s 428us/sample - loss: 6.0940 - class_1_loss: 2.3977 - class_2_loss: 2.3977 - class_final_loss: 2.3977 - rate_loss: 0.0988 - class_1_accuracy: 0.0356 - class_2_accuracy: 0.0265 - class_final_accuracy: 0.0348 - val_loss: 6.0427 - val_class_1_loss: 2.3632 - val_class_2_loss: 2.3632 - val_class_final_loss: 2.3632 - val_rate_loss: 0.1554 - val_class_1_accuracy: 0.0864 - val_class_2_accuracy: 0.0864 - val_class_final_accuracy: 0.0864\n",
      "Epoch 45/200\n",
      "73917/73917 [==============================] - 32s 430us/sample - loss: 6.0942 - class_1_loss: 2.3977 - class_2_loss: 2.3978 - class_final_loss: 2.3977 - rate_loss: 0.0988 - class_1_accuracy: 0.1088 - class_2_accuracy: 0.0728 - class_final_accuracy: 0.1094 - val_loss: 6.0432 - val_class_1_loss: 2.3633 - val_class_2_loss: 2.3634 - val_class_final_loss: 2.3633 - val_rate_loss: 0.1556 - val_class_1_accuracy: 0.0448 - val_class_2_accuracy: 0.0448 - val_class_final_accuracy: 0.0192\n",
      "Epoch 46/200\n",
      "73917/73917 [==============================] - 31s 419us/sample - loss: 6.0940 - class_1_loss: 2.3979 - class_2_loss: 2.3980 - class_final_loss: 2.3979 - rate_loss: 0.0988 - class_1_accuracy: 0.0360 - class_2_accuracy: 0.0381 - class_final_accuracy: 0.0363 - val_loss: 6.0480 - val_class_1_loss: 2.3635 - val_class_2_loss: 2.3635 - val_class_final_loss: 2.3639 - val_rate_loss: 0.1598 - val_class_1_accuracy: 0.0448 - val_class_2_accuracy: 0.0448 - val_class_final_accuracy: 0.0264\n",
      "Epoch 47/200\n",
      "73917/73917 [==============================] - 31s 426us/sample - loss: 6.0942 - class_1_loss: 2.3986 - class_2_loss: 2.3988 - class_final_loss: 2.3987 - rate_loss: 0.0988 - class_1_accuracy: 0.0712 - class_2_accuracy: 0.0600 - class_final_accuracy: 0.0669 - val_loss: 6.0481 - val_class_1_loss: 2.3634 - val_class_2_loss: 2.3635 - val_class_final_loss: 2.3634 - val_rate_loss: 0.1603 - val_class_1_accuracy: 0.0264 - val_class_2_accuracy: 0.0264 - val_class_final_accuracy: 0.0264\n",
      "Epoch 48/200\n",
      "73917/73917 [==============================] - 32s 428us/sample - loss: 6.0941 - class_1_loss: 2.3987 - class_2_loss: 2.3986 - class_final_loss: 2.3986 - rate_loss: 0.0988 - class_1_accuracy: 0.0442 - class_2_accuracy: 0.0394 - class_final_accuracy: 0.0471 - val_loss: 6.0450 - val_class_1_loss: 2.3633 - val_class_2_loss: 2.3634 - val_class_final_loss: 2.3633 - val_rate_loss: 0.1574 - val_class_1_accuracy: 0.1480 - val_class_2_accuracy: 0.1480 - val_class_final_accuracy: 0.1480\n",
      "Epoch 49/200\n",
      "73917/73917 [==============================] - 32s 430us/sample - loss: 6.0945 - class_1_loss: 2.3977 - class_2_loss: 2.3981 - class_final_loss: 2.3977 - rate_loss: 0.0988 - class_1_accuracy: 0.0594 - class_2_accuracy: 0.0538 - class_final_accuracy: 0.0637 - val_loss: 6.0444 - val_class_1_loss: 2.3635 - val_class_2_loss: 2.3636 - val_class_final_loss: 2.3635 - val_rate_loss: 0.1563 - val_class_1_accuracy: 0.0582 - val_class_2_accuracy: 0.0095 - val_class_final_accuracy: 0.0582\n",
      "Epoch 50/200\n",
      "73917/73917 [==============================] - 32s 428us/sample - loss: 6.0940 - class_1_loss: 2.3980 - class_2_loss: 2.3980 - class_final_loss: 2.3980 - rate_loss: 0.0988 - class_1_accuracy: 0.0766 - class_2_accuracy: 0.0816 - class_final_accuracy: 0.0772 - val_loss: 6.0497 - val_class_1_loss: 2.3636 - val_class_2_loss: 2.3636 - val_class_final_loss: 2.3636 - val_rate_loss: 0.1615 - val_class_1_accuracy: 0.0864 - val_class_2_accuracy: 0.0864 - val_class_final_accuracy: 0.0864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/200\n",
      "73917/73917 [==============================] - 32s 430us/sample - loss: 6.0940 - class_1_loss: 2.3975 - class_2_loss: 2.3975 - class_final_loss: 2.3975 - rate_loss: 0.0988 - class_1_accuracy: 0.0750 - class_2_accuracy: 0.0770 - class_final_accuracy: 0.0682 - val_loss: 6.0460 - val_class_1_loss: 2.3636 - val_class_2_loss: 2.3637 - val_class_final_loss: 2.3637 - val_rate_loss: 0.1576 - val_class_1_accuracy: 0.0264 - val_class_2_accuracy: 0.0095 - val_class_final_accuracy: 0.0095\n",
      "Epoch 52/200\n",
      "73917/73917 [==============================] - 32s 430us/sample - loss: 6.0941 - class_1_loss: 2.3979 - class_2_loss: 2.3977 - class_final_loss: 2.3978 - rate_loss: 0.0988 - class_1_accuracy: 0.0310 - class_2_accuracy: 0.0277 - class_final_accuracy: 0.0440 - val_loss: 6.0452 - val_class_1_loss: 2.3635 - val_class_2_loss: 2.3635 - val_class_final_loss: 2.3635 - val_rate_loss: 0.1573 - val_class_1_accuracy: 0.1121 - val_class_2_accuracy: 0.1121 - val_class_final_accuracy: 0.1121\n",
      "Epoch 53/200\n",
      "73917/73917 [==============================] - 31s 426us/sample - loss: 6.0951 - class_1_loss: 2.3988 - class_2_loss: 2.3985 - class_final_loss: 2.3987 - rate_loss: 0.0988 - class_1_accuracy: 0.0734 - class_2_accuracy: 0.0900 - class_final_accuracy: 0.0812 - val_loss: 6.0426 - val_class_1_loss: 2.3635 - val_class_2_loss: 2.3635 - val_class_final_loss: 2.3635 - val_rate_loss: 0.1547 - val_class_1_accuracy: 0.0864 - val_class_2_accuracy: 0.1480 - val_class_final_accuracy: 0.0864\n",
      "Epoch 54/200\n",
      "73917/73917 [==============================] - 32s 432us/sample - loss: 6.0959 - class_1_loss: 2.3986 - class_2_loss: 2.3988 - class_final_loss: 2.3989 - rate_loss: 0.0988 - class_1_accuracy: 0.0421 - class_2_accuracy: 0.0611 - class_final_accuracy: 0.0594 - val_loss: 6.0441 - val_class_1_loss: 2.3636 - val_class_2_loss: 2.3636 - val_class_final_loss: 2.3636 - val_rate_loss: 0.1559 - val_class_1_accuracy: 0.0264 - val_class_2_accuracy: 0.0264 - val_class_final_accuracy: 0.0864\n",
      "Epoch 55/200\n",
      "73917/73917 [==============================] - 32s 432us/sample - loss: 6.0948 - class_1_loss: 2.3983 - class_2_loss: 2.3982 - class_final_loss: 2.3990 - rate_loss: 0.0989 - class_1_accuracy: 0.0297 - class_2_accuracy: 0.0312 - class_final_accuracy: 0.0289 - val_loss: 6.0451 - val_class_1_loss: 2.3635 - val_class_2_loss: 2.3634 - val_class_final_loss: 2.3638 - val_rate_loss: 0.1571 - val_class_1_accuracy: 0.3661 - val_class_2_accuracy: 0.3661 - val_class_final_accuracy: 0.0095\n",
      "Epoch 56/200\n",
      "73917/73917 [==============================] - 32s 430us/sample - loss: 6.0947 - class_1_loss: 2.3983 - class_2_loss: 2.3984 - class_final_loss: 2.3989 - rate_loss: 0.0988 - class_1_accuracy: 0.1793 - class_2_accuracy: 0.1557 - class_final_accuracy: 0.0478 - val_loss: 6.0484 - val_class_1_loss: 2.3635 - val_class_2_loss: 2.3635 - val_class_final_loss: 2.3637 - val_rate_loss: 0.1602 - val_class_1_accuracy: 0.0264 - val_class_2_accuracy: 0.0264 - val_class_final_accuracy: 0.0095\n",
      "Epoch 57/200\n",
      "73917/73917 [==============================] - 32s 431us/sample - loss: 6.0945 - class_1_loss: 2.3985 - class_2_loss: 2.3990 - class_final_loss: 2.3986 - rate_loss: 0.0988 - class_1_accuracy: 0.0746 - class_2_accuracy: 0.0710 - class_final_accuracy: 0.0504 - val_loss: 6.0481 - val_class_1_loss: 2.3635 - val_class_2_loss: 2.3635 - val_class_final_loss: 2.3636 - val_rate_loss: 0.1599 - val_class_1_accuracy: 0.1480 - val_class_2_accuracy: 0.1480 - val_class_final_accuracy: 0.0095\n",
      "Epoch 58/200\n",
      "73917/73917 [==============================] - 32s 426us/sample - loss: 6.0942 - class_1_loss: 2.3979 - class_2_loss: 2.3979 - class_final_loss: 2.3980 - rate_loss: 0.0988 - class_1_accuracy: 0.0693 - class_2_accuracy: 0.0627 - class_final_accuracy: 0.0559 - val_loss: 6.0489 - val_class_1_loss: 2.3637 - val_class_2_loss: 2.3637 - val_class_final_loss: 2.3637 - val_rate_loss: 0.1605 - val_class_1_accuracy: 0.0095 - val_class_2_accuracy: 0.0095 - val_class_final_accuracy: 0.0095\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0d770ebc18>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                  min_delta=0.0005,\n",
    "                                                  patience=50, verbose=0, mode='auto')\n",
    "\n",
    "CNNLSTM_model.fit(x=X_train,\n",
    "              y={\n",
    "                  #'num_mis': num_mis_train,\n",
    "                  'class_1': class_train,\n",
    "                  'class_2': class_train,\n",
    "                  'class_final': class_train,\n",
    "                  'rate': rate_train},\n",
    "              validation_data=(X_val, {#'num_mis': num_mis_val,\n",
    "                                       'class_1': class_val,\n",
    "                                       'class_2': class_val,\n",
    "                                       'class_final': class_val,\n",
    "                                       'rate': rate_val}),\n",
    "              class_weight={\n",
    "                  'class_1' : class_weights_dict,\n",
    "                  'class_2' : class_weights_dict,\n",
    "                  'class_final' : class_weights_dict},\n",
    "              sample_weight={'rate' : sample_weight},\n",
    "              shuffle=True,\n",
    "              epochs=200,\n",
    "              batch_size=128,\n",
    "              verbose=1,\n",
    "              callbacks=[early_stopping]\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction = regression_model.predict(X_test)\n",
    "test_prediction = np.array(test_prediction).reshape(-1,)\n",
    "test_true = rate_test.reshape(-1,)\n",
    "\n",
    "test_correlation = np.corrcoef(test_prediction, test_true).flatten()[1]\n",
    "pearson_corr = pearsonr(test_prediction, test_true)\n",
    "spearman_corr = spearmanr(test_prediction, test_true)\n",
    "print('Correlation : {}'.format(test_correlation))\n",
    "print('Pearson Correlation : {}'.format(pearson_corr[0]))\n",
    "print('Spearman Correlation : {}'.format(spearman_corr[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
